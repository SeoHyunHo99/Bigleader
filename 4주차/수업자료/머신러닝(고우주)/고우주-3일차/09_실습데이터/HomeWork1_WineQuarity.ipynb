{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1324b5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "0  white            7.0              0.27         0.36            20.7   \n",
       "1  white            6.3              0.30         0.34             1.6   \n",
       "2  white            8.1              0.28         0.40             6.9   \n",
       "3  white            7.2              0.23         0.32             8.5   \n",
       "4  white            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates  alcohol  quality_range  \n",
       "0       0.45      8.8              1  \n",
       "1       0.49      9.5              1  \n",
       "2       0.44     10.1              1  \n",
       "3       0.40      9.9              1  \n",
       "4       0.40      9.9              1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "WineQuality = pd.read_csv(\"data/winequalityN_imblance.csv\")\n",
    "WineQuality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d6da24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>red</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>red</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>red</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>red</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>red</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "0     white            7.0             0.270         0.36            20.7   \n",
       "1     white            6.3             0.300         0.34             1.6   \n",
       "2     white            8.1             0.280         0.40             6.9   \n",
       "3     white            7.2             0.230         0.32             8.5   \n",
       "4     white            7.2             0.230         0.32             8.5   \n",
       "...     ...            ...               ...          ...             ...   \n",
       "6492    red            6.2             0.600         0.08             2.0   \n",
       "6493    red            5.9             0.550         0.10             2.2   \n",
       "6494    red            6.3             0.510         0.13             2.3   \n",
       "6495    red            5.9             0.645         0.12             2.0   \n",
       "6496    red            6.0             0.310         0.47             3.6   \n",
       "\n",
       "      chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  \\\n",
       "0         0.045                 45.0                 170.0  1.00100  3.00   \n",
       "1         0.049                 14.0                 132.0  0.99400  3.30   \n",
       "2         0.050                 30.0                  97.0  0.99510  3.26   \n",
       "3         0.058                 47.0                 186.0  0.99560  3.19   \n",
       "4         0.058                 47.0                 186.0  0.99560  3.19   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "6492      0.090                 32.0                  44.0  0.99490  3.45   \n",
       "6493      0.062                 39.0                  51.0  0.99512  3.52   \n",
       "6494      0.076                 29.0                  40.0  0.99574  3.42   \n",
       "6495      0.075                 32.0                  44.0  0.99547  3.57   \n",
       "6496      0.067                 18.0                  42.0  0.99549  3.39   \n",
       "\n",
       "      sulphates  alcohol  quality_range  \n",
       "0          0.45      8.8              1  \n",
       "1          0.49      9.5              1  \n",
       "2          0.44     10.1              1  \n",
       "3          0.40      9.9              1  \n",
       "4          0.40      9.9              1  \n",
       "...         ...      ...            ...  \n",
       "6492       0.58     10.5              1  \n",
       "6493        NaN     11.2              1  \n",
       "6494       0.75     11.0              1  \n",
       "6495       0.71     10.2              1  \n",
       "6496       0.66     11.0              1  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WineQuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735bf8af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   type                  6497 non-null   object \n",
      " 1   fixed_acidity         6487 non-null   float64\n",
      " 2   volatile_acidity      6489 non-null   float64\n",
      " 3   citric_acid           6494 non-null   float64\n",
      " 4   residual_sugar        6495 non-null   float64\n",
      " 5   chlorides             6495 non-null   float64\n",
      " 6   free_sulfur_dioxide   6497 non-null   float64\n",
      " 7   total_sulfur_dioxide  6497 non-null   float64\n",
      " 8   density               6497 non-null   float64\n",
      " 9   pH                    6488 non-null   float64\n",
      " 10  sulphates             6493 non-null   float64\n",
      " 11  alcohol               6497 non-null   float64\n",
      " 12  quality_range         6497 non-null   int64  \n",
      "dtypes: float64(11), int64(1), object(1)\n",
      "memory usage: 660.0+ KB\n"
     ]
    }
   ],
   "source": [
    "WineQuality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86121227",
   "metadata": {},
   "outputs": [],
   "source": [
    "WineQuality = WineQuality.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06a8b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6463 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   type                  6463 non-null   object \n",
      " 1   fixed_acidity         6463 non-null   float64\n",
      " 2   volatile_acidity      6463 non-null   float64\n",
      " 3   citric_acid           6463 non-null   float64\n",
      " 4   residual_sugar        6463 non-null   float64\n",
      " 5   chlorides             6463 non-null   float64\n",
      " 6   free_sulfur_dioxide   6463 non-null   float64\n",
      " 7   total_sulfur_dioxide  6463 non-null   float64\n",
      " 8   density               6463 non-null   float64\n",
      " 9   pH                    6463 non-null   float64\n",
      " 10  sulphates             6463 non-null   float64\n",
      " 11  alcohol               6463 non-null   float64\n",
      " 12  quality_range         6463 non-null   int64  \n",
      "dtypes: float64(11), int64(1), object(1)\n",
      "memory usage: 706.9+ KB\n"
     ]
    }
   ],
   "source": [
    "WineQuality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "442c0afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6463"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WineQuality[\"type\"].isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5323fd96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "WineQuality[\"type\"] = WineQuality[\"type\"].replace(\"white\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd025774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "WineQuality[\"type\"] = WineQuality[\"type\"].replace(\"red\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "006e2b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "6491    1\n",
       "6492    1\n",
       "6494    1\n",
       "6495    1\n",
       "6496    1\n",
       "Name: type, Length: 6463, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WineQuality[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f729632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ccbd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = WineQuality.iloc[:, :-1]\n",
    "y = WineQuality.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99cee812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coun_1 6219\n",
      "coun_0 244\n"
     ]
    }
   ],
   "source": [
    "count_1 = 0\n",
    "count_0 = 0\n",
    "for i in y:\n",
    "    if i == 1.0:\n",
    "        count_1 += 1\n",
    "    else:\n",
    "        count_0 += 1\n",
    "print(\"coun_1\",count_1)\n",
    "print(\"coun_0\",count_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aee64372",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6463 entries, 0 to 6496\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   type                  6463 non-null   int64  \n",
      " 1   fixed_acidity         6463 non-null   float64\n",
      " 2   volatile_acidity      6463 non-null   float64\n",
      " 3   citric_acid           6463 non-null   float64\n",
      " 4   residual_sugar        6463 non-null   float64\n",
      " 5   chlorides             6463 non-null   float64\n",
      " 6   free_sulfur_dioxide   6463 non-null   float64\n",
      " 7   total_sulfur_dioxide  6463 non-null   float64\n",
      " 8   density               6463 non-null   float64\n",
      " 9   pH                    6463 non-null   float64\n",
      " 10  sulphates             6463 non-null   float64\n",
      " 11  alcohol               6463 non-null   float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 656.4 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee03f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "# 필요 모듈 임포트\n",
    "import imblearn\n",
    "print(imblearn.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# 필요 함수 정의\n",
    "def count_and_plot(y): \n",
    "    counter = Counter(y)\n",
    "    for k,v in counter.items():\n",
    "        print('Class=%d, n=%d (%.3f%%)' % (k, v, v / len(y) * 100))\n",
    "    pyplot.bar(counter.keys(), counter.values())\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f9afa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 오버 샘플링\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# X_resampled, y_resampled = RandomOverSampler(random_state=0).fit_resample(X, y)\n",
    "# count_and_plot(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68f6042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 언더 샘플링\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# X_resampled, y_resampled = RandomUnderSampler(random_state=0).fit_resample(X, y)\n",
    "# count_and_plot(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5553d890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=1, n=6219 (50.000%)\n",
      "Class=0, n=6219 (50.000%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X, y = SMOTE(random_state=0).fit_resample(X, y)\n",
    "count_and_plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b12c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5d177ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cost-sensitive learning\n",
    "\n",
    "# from numpy import mean, std\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# def evaluate_model(X_, y_, model_):\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "#     scores = cross_val_score(model_, X_, y_, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#     return scores\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators=1000)\n",
    "# scores = evaluate_model(X, y, model)\n",
    "# print('Mean Accuracy No weight: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# weights = {1:1.0, 2:1.0, 3:2.0, 5:2.0, 6:2.0, 7:2.0}\n",
    "# model = RandomForestClassifier(n_estimators=1000, class_weight=weights)\n",
    "# scores = evaluate_model(X, y, model)\n",
    "# print('Mean Accuracy    weight: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74dbd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4d3bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: [0.94 0.97 0.99 0.99 0.87]\n",
      "Accuracy mean: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Display accuracy\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "\n",
    "# Display mean accuracy\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "248cfb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ce4aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: [0.98 0.98 0.99 0.98 0.98]\n",
      "Accuracy mean: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "# Display accuracy\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "\n",
    "# Display mean accuracy\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "140dfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65afd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, random=False): \n",
    "    \n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    \n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1, random_state=2)\n",
    "    else:\n",
    "        # Instantiate GridSearchCV as grid_reg\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    \n",
    "    # Fit grid_reg on X_train and y_train\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    # Extract best params\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    # Print best params\n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "    # Compute best score\n",
    "    best_score = grid.best_score_\n",
    "\n",
    "    # Print best score\n",
    "    print(\"Best score: {:.5f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b188d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'n_estimators': 200}\n",
      "Best score: 0.98585\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators':[100, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7a3c23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'learning_rate': 0.4}\n",
      "Best score: 0.98537\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcea2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'max_depth': 8}\n",
      "Best score: 0.98489\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "197c2b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'gamma': 0.1}\n",
      "Best score: 0.98400\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'gamma':[0, 0.01, 0.1, 0.5, 1, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bbafd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'min_child_weight': 2}\n",
      "Best score: 0.98408\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'min_child_weight':[1, 2, 3, 4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "931e6be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'subsample': 0.8}\n",
      "Best score: 0.98440\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b13c53f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'colsample_bytree': 0.9}\n",
      "Best score: 0.98440\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bytree':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8679c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcfdde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e7b52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fa4fc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4686\n",
       "1    4642\n",
       "Name: quality_range, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "078298e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1577\n",
       "0    1533\n",
       "Name: quality_range, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5a61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8eb04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0867222b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.20000\n",
      "[1]\tvalidation_0-error:0.15788\n",
      "[2]\tvalidation_0-error:0.14855\n",
      "[3]\tvalidation_0-error:0.13859\n",
      "[4]\tvalidation_0-error:0.13473\n",
      "[5]\tvalidation_0-error:0.11865\n",
      "[6]\tvalidation_0-error:0.10868\n",
      "[7]\tvalidation_0-error:0.10096\n",
      "[8]\tvalidation_0-error:0.09646\n",
      "[9]\tvalidation_0-error:0.09261\n",
      "[10]\tvalidation_0-error:0.08810\n",
      "[11]\tvalidation_0-error:0.08360\n",
      "[12]\tvalidation_0-error:0.08039\n",
      "[13]\tvalidation_0-error:0.07749\n",
      "[14]\tvalidation_0-error:0.07396\n",
      "[15]\tvalidation_0-error:0.07203\n",
      "[16]\tvalidation_0-error:0.07299\n",
      "[17]\tvalidation_0-error:0.07170\n",
      "[18]\tvalidation_0-error:0.06367\n",
      "[19]\tvalidation_0-error:0.06174\n",
      "[20]\tvalidation_0-error:0.06013\n",
      "[21]\tvalidation_0-error:0.05691\n",
      "[22]\tvalidation_0-error:0.05563\n",
      "[23]\tvalidation_0-error:0.05241\n",
      "[24]\tvalidation_0-error:0.05112\n",
      "[25]\tvalidation_0-error:0.05112\n",
      "[26]\tvalidation_0-error:0.04920\n",
      "[27]\tvalidation_0-error:0.04727\n",
      "[28]\tvalidation_0-error:0.04759\n",
      "[29]\tvalidation_0-error:0.04823\n",
      "[30]\tvalidation_0-error:0.04823\n",
      "[31]\tvalidation_0-error:0.04437\n",
      "[32]\tvalidation_0-error:0.04437\n",
      "[33]\tvalidation_0-error:0.04180\n",
      "[34]\tvalidation_0-error:0.04019\n",
      "[35]\tvalidation_0-error:0.03826\n",
      "[36]\tvalidation_0-error:0.03826\n",
      "[37]\tvalidation_0-error:0.03666\n",
      "[38]\tvalidation_0-error:0.03601\n",
      "[39]\tvalidation_0-error:0.03505\n",
      "[40]\tvalidation_0-error:0.03537\n",
      "[41]\tvalidation_0-error:0.03473\n",
      "[42]\tvalidation_0-error:0.03312\n",
      "[43]\tvalidation_0-error:0.03280\n",
      "[44]\tvalidation_0-error:0.03183\n",
      "[45]\tvalidation_0-error:0.02958\n",
      "[46]\tvalidation_0-error:0.02862\n",
      "[47]\tvalidation_0-error:0.02862\n",
      "[48]\tvalidation_0-error:0.02830\n",
      "[49]\tvalidation_0-error:0.02765\n",
      "[50]\tvalidation_0-error:0.02733\n",
      "[51]\tvalidation_0-error:0.02604\n",
      "[52]\tvalidation_0-error:0.02540\n",
      "[53]\tvalidation_0-error:0.02540\n",
      "[54]\tvalidation_0-error:0.02508\n",
      "[55]\tvalidation_0-error:0.02476\n",
      "[56]\tvalidation_0-error:0.02412\n",
      "[57]\tvalidation_0-error:0.02251\n",
      "[58]\tvalidation_0-error:0.02186\n",
      "[59]\tvalidation_0-error:0.02154\n",
      "[60]\tvalidation_0-error:0.02186\n",
      "[61]\tvalidation_0-error:0.02186\n",
      "[62]\tvalidation_0-error:0.02186\n",
      "[63]\tvalidation_0-error:0.02154\n",
      "[64]\tvalidation_0-error:0.02154\n",
      "[65]\tvalidation_0-error:0.02154\n",
      "[66]\tvalidation_0-error:0.02090\n",
      "[67]\tvalidation_0-error:0.02154\n",
      "[68]\tvalidation_0-error:0.02122\n",
      "[69]\tvalidation_0-error:0.02090\n",
      "[70]\tvalidation_0-error:0.02090\n",
      "[71]\tvalidation_0-error:0.02026\n",
      "[72]\tvalidation_0-error:0.01994\n",
      "[73]\tvalidation_0-error:0.01994\n",
      "[74]\tvalidation_0-error:0.01929\n",
      "[75]\tvalidation_0-error:0.01833\n",
      "[76]\tvalidation_0-error:0.01865\n",
      "[77]\tvalidation_0-error:0.01929\n",
      "[78]\tvalidation_0-error:0.01929\n",
      "[79]\tvalidation_0-error:0.01929\n",
      "[80]\tvalidation_0-error:0.01929\n",
      "[81]\tvalidation_0-error:0.01801\n",
      "[82]\tvalidation_0-error:0.01801\n",
      "[83]\tvalidation_0-error:0.01801\n",
      "[84]\tvalidation_0-error:0.01801\n",
      "[85]\tvalidation_0-error:0.01801\n",
      "[86]\tvalidation_0-error:0.01736\n",
      "[87]\tvalidation_0-error:0.01704\n",
      "[88]\tvalidation_0-error:0.01704\n",
      "[89]\tvalidation_0-error:0.01736\n",
      "[90]\tvalidation_0-error:0.01736\n",
      "[91]\tvalidation_0-error:0.01736\n",
      "[92]\tvalidation_0-error:0.01672\n",
      "[93]\tvalidation_0-error:0.01672\n",
      "[94]\tvalidation_0-error:0.01704\n",
      "[95]\tvalidation_0-error:0.01736\n",
      "[96]\tvalidation_0-error:0.01801\n",
      "[97]\tvalidation_0-error:0.01801\n",
      "[98]\tvalidation_0-error:0.01704\n",
      "[99]\tvalidation_0-error:0.01672\n",
      "Accuracy: 98.33%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic',scale_pos_weight = 1 ,random_state=2)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric='error'\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ceefc203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.20000\n",
      "[1]\tvalidation_0-error:0.15788\n",
      "[2]\tvalidation_0-error:0.14855\n",
      "[3]\tvalidation_0-error:0.13859\n",
      "[4]\tvalidation_0-error:0.13473\n",
      "[5]\tvalidation_0-error:0.11865\n",
      "[6]\tvalidation_0-error:0.10868\n",
      "[7]\tvalidation_0-error:0.10096\n",
      "[8]\tvalidation_0-error:0.09646\n",
      "[9]\tvalidation_0-error:0.09261\n",
      "[10]\tvalidation_0-error:0.08810\n",
      "[11]\tvalidation_0-error:0.08360\n",
      "[12]\tvalidation_0-error:0.08039\n",
      "[13]\tvalidation_0-error:0.07749\n",
      "[14]\tvalidation_0-error:0.07396\n",
      "[15]\tvalidation_0-error:0.07203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\tvalidation_0-error:0.07299\n",
      "[17]\tvalidation_0-error:0.07170\n",
      "[18]\tvalidation_0-error:0.06367\n",
      "[19]\tvalidation_0-error:0.06174\n",
      "[20]\tvalidation_0-error:0.06013\n",
      "[21]\tvalidation_0-error:0.05691\n",
      "[22]\tvalidation_0-error:0.05563\n",
      "[23]\tvalidation_0-error:0.05241\n",
      "[24]\tvalidation_0-error:0.05112\n",
      "[25]\tvalidation_0-error:0.05112\n",
      "[26]\tvalidation_0-error:0.04920\n",
      "[27]\tvalidation_0-error:0.04727\n",
      "[28]\tvalidation_0-error:0.04759\n",
      "[29]\tvalidation_0-error:0.04823\n",
      "[30]\tvalidation_0-error:0.04823\n",
      "[31]\tvalidation_0-error:0.04437\n",
      "[32]\tvalidation_0-error:0.04437\n",
      "[33]\tvalidation_0-error:0.04180\n",
      "[34]\tvalidation_0-error:0.04019\n",
      "[35]\tvalidation_0-error:0.03826\n",
      "[36]\tvalidation_0-error:0.03826\n",
      "[37]\tvalidation_0-error:0.03666\n",
      "[38]\tvalidation_0-error:0.03601\n",
      "[39]\tvalidation_0-error:0.03505\n",
      "[40]\tvalidation_0-error:0.03537\n",
      "[41]\tvalidation_0-error:0.03473\n",
      "[42]\tvalidation_0-error:0.03312\n",
      "[43]\tvalidation_0-error:0.03280\n",
      "[44]\tvalidation_0-error:0.03183\n",
      "[45]\tvalidation_0-error:0.02958\n",
      "[46]\tvalidation_0-error:0.02862\n",
      "[47]\tvalidation_0-error:0.02862\n",
      "[48]\tvalidation_0-error:0.02830\n",
      "[49]\tvalidation_0-error:0.02765\n",
      "[50]\tvalidation_0-error:0.02733\n",
      "[51]\tvalidation_0-error:0.02604\n",
      "[52]\tvalidation_0-error:0.02540\n",
      "[53]\tvalidation_0-error:0.02540\n",
      "[54]\tvalidation_0-error:0.02508\n",
      "[55]\tvalidation_0-error:0.02476\n",
      "[56]\tvalidation_0-error:0.02412\n",
      "[57]\tvalidation_0-error:0.02251\n",
      "[58]\tvalidation_0-error:0.02186\n",
      "[59]\tvalidation_0-error:0.02154\n",
      "[60]\tvalidation_0-error:0.02186\n",
      "[61]\tvalidation_0-error:0.02186\n",
      "[62]\tvalidation_0-error:0.02186\n",
      "[63]\tvalidation_0-error:0.02154\n",
      "[64]\tvalidation_0-error:0.02154\n",
      "[65]\tvalidation_0-error:0.02154\n",
      "[66]\tvalidation_0-error:0.02090\n",
      "[67]\tvalidation_0-error:0.02154\n",
      "[68]\tvalidation_0-error:0.02122\n",
      "[69]\tvalidation_0-error:0.02090\n",
      "[70]\tvalidation_0-error:0.02090\n",
      "[71]\tvalidation_0-error:0.02026\n",
      "[72]\tvalidation_0-error:0.01994\n",
      "[73]\tvalidation_0-error:0.01994\n",
      "[74]\tvalidation_0-error:0.01929\n",
      "[75]\tvalidation_0-error:0.01833\n",
      "[76]\tvalidation_0-error:0.01865\n",
      "[77]\tvalidation_0-error:0.01929\n",
      "[78]\tvalidation_0-error:0.01929\n",
      "[79]\tvalidation_0-error:0.01929\n",
      "[80]\tvalidation_0-error:0.01929\n",
      "[81]\tvalidation_0-error:0.01801\n",
      "[82]\tvalidation_0-error:0.01801\n",
      "[83]\tvalidation_0-error:0.01801\n",
      "[84]\tvalidation_0-error:0.01801\n",
      "[85]\tvalidation_0-error:0.01801\n",
      "[86]\tvalidation_0-error:0.01736\n",
      "[87]\tvalidation_0-error:0.01704\n",
      "[88]\tvalidation_0-error:0.01704\n",
      "[89]\tvalidation_0-error:0.01736\n",
      "[90]\tvalidation_0-error:0.01736\n",
      "[91]\tvalidation_0-error:0.01736\n",
      "[92]\tvalidation_0-error:0.01672\n",
      "[93]\tvalidation_0-error:0.01672\n",
      "[94]\tvalidation_0-error:0.01704\n",
      "[95]\tvalidation_0-error:0.01736\n",
      "[96]\tvalidation_0-error:0.01801\n",
      "[97]\tvalidation_0-error:0.01801\n",
      "[98]\tvalidation_0-error:0.01704\n",
      "[99]\tvalidation_0-error:0.01672\n",
      "Accuracy: 98.33%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric=\"error\"\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, early_stopping_rounds=10, verbose=True)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d3cc61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.20000\n",
      "[1]\tvalidation_0-error:0.15788\n",
      "[2]\tvalidation_0-error:0.14855\n",
      "[3]\tvalidation_0-error:0.13859\n",
      "[4]\tvalidation_0-error:0.13473\n",
      "[5]\tvalidation_0-error:0.11865\n",
      "[6]\tvalidation_0-error:0.10868\n",
      "[7]\tvalidation_0-error:0.10096\n",
      "[8]\tvalidation_0-error:0.09646\n",
      "[9]\tvalidation_0-error:0.09261\n",
      "[10]\tvalidation_0-error:0.08810\n",
      "[11]\tvalidation_0-error:0.08360\n",
      "[12]\tvalidation_0-error:0.08039\n",
      "[13]\tvalidation_0-error:0.07749\n",
      "[14]\tvalidation_0-error:0.07396\n",
      "[15]\tvalidation_0-error:0.07203\n",
      "[16]\tvalidation_0-error:0.07299\n",
      "[17]\tvalidation_0-error:0.07170\n",
      "[18]\tvalidation_0-error:0.06367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tvalidation_0-error:0.06174\n",
      "[20]\tvalidation_0-error:0.06013\n",
      "[21]\tvalidation_0-error:0.05691\n",
      "[22]\tvalidation_0-error:0.05563\n",
      "[23]\tvalidation_0-error:0.05241\n",
      "[24]\tvalidation_0-error:0.05112\n",
      "[25]\tvalidation_0-error:0.05112\n",
      "[26]\tvalidation_0-error:0.04920\n",
      "[27]\tvalidation_0-error:0.04727\n",
      "[28]\tvalidation_0-error:0.04759\n",
      "[29]\tvalidation_0-error:0.04823\n",
      "[30]\tvalidation_0-error:0.04823\n",
      "[31]\tvalidation_0-error:0.04437\n",
      "[32]\tvalidation_0-error:0.04437\n",
      "[33]\tvalidation_0-error:0.04180\n",
      "[34]\tvalidation_0-error:0.04019\n",
      "[35]\tvalidation_0-error:0.03826\n",
      "[36]\tvalidation_0-error:0.03826\n",
      "[37]\tvalidation_0-error:0.03666\n",
      "[38]\tvalidation_0-error:0.03601\n",
      "[39]\tvalidation_0-error:0.03505\n",
      "[40]\tvalidation_0-error:0.03537\n",
      "[41]\tvalidation_0-error:0.03473\n",
      "[42]\tvalidation_0-error:0.03312\n",
      "[43]\tvalidation_0-error:0.03280\n",
      "[44]\tvalidation_0-error:0.03183\n",
      "[45]\tvalidation_0-error:0.02958\n",
      "[46]\tvalidation_0-error:0.02862\n",
      "[47]\tvalidation_0-error:0.02862\n",
      "[48]\tvalidation_0-error:0.02830\n",
      "[49]\tvalidation_0-error:0.02765\n",
      "[50]\tvalidation_0-error:0.02733\n",
      "[51]\tvalidation_0-error:0.02604\n",
      "[52]\tvalidation_0-error:0.02540\n",
      "[53]\tvalidation_0-error:0.02540\n",
      "[54]\tvalidation_0-error:0.02508\n",
      "[55]\tvalidation_0-error:0.02476\n",
      "[56]\tvalidation_0-error:0.02412\n",
      "[57]\tvalidation_0-error:0.02251\n",
      "[58]\tvalidation_0-error:0.02186\n",
      "[59]\tvalidation_0-error:0.02154\n",
      "[60]\tvalidation_0-error:0.02186\n",
      "[61]\tvalidation_0-error:0.02186\n",
      "[62]\tvalidation_0-error:0.02186\n",
      "[63]\tvalidation_0-error:0.02154\n",
      "[64]\tvalidation_0-error:0.02154\n",
      "[65]\tvalidation_0-error:0.02154\n",
      "[66]\tvalidation_0-error:0.02090\n",
      "[67]\tvalidation_0-error:0.02154\n",
      "[68]\tvalidation_0-error:0.02122\n",
      "[69]\tvalidation_0-error:0.02090\n",
      "[70]\tvalidation_0-error:0.02090\n",
      "[71]\tvalidation_0-error:0.02026\n",
      "[72]\tvalidation_0-error:0.01994\n",
      "[73]\tvalidation_0-error:0.01994\n",
      "[74]\tvalidation_0-error:0.01929\n",
      "[75]\tvalidation_0-error:0.01833\n",
      "[76]\tvalidation_0-error:0.01865\n",
      "[77]\tvalidation_0-error:0.01929\n",
      "[78]\tvalidation_0-error:0.01929\n",
      "[79]\tvalidation_0-error:0.01929\n",
      "[80]\tvalidation_0-error:0.01929\n",
      "[81]\tvalidation_0-error:0.01801\n",
      "[82]\tvalidation_0-error:0.01801\n",
      "[83]\tvalidation_0-error:0.01801\n",
      "[84]\tvalidation_0-error:0.01801\n",
      "[85]\tvalidation_0-error:0.01801\n",
      "[86]\tvalidation_0-error:0.01736\n",
      "[87]\tvalidation_0-error:0.01704\n",
      "[88]\tvalidation_0-error:0.01704\n",
      "[89]\tvalidation_0-error:0.01736\n",
      "[90]\tvalidation_0-error:0.01736\n",
      "[91]\tvalidation_0-error:0.01736\n",
      "[92]\tvalidation_0-error:0.01672\n",
      "[93]\tvalidation_0-error:0.01672\n",
      "[94]\tvalidation_0-error:0.01704\n",
      "[95]\tvalidation_0-error:0.01736\n",
      "[96]\tvalidation_0-error:0.01801\n",
      "[97]\tvalidation_0-error:0.01801\n",
      "[98]\tvalidation_0-error:0.01704\n",
      "[99]\tvalidation_0-error:0.01672\n",
      "[100]\tvalidation_0-error:0.01768\n",
      "[101]\tvalidation_0-error:0.01704\n",
      "[102]\tvalidation_0-error:0.01704\n",
      "[103]\tvalidation_0-error:0.01672\n",
      "[104]\tvalidation_0-error:0.01704\n",
      "[105]\tvalidation_0-error:0.01704\n",
      "[106]\tvalidation_0-error:0.01704\n",
      "[107]\tvalidation_0-error:0.01704\n",
      "[108]\tvalidation_0-error:0.01704\n",
      "[109]\tvalidation_0-error:0.01736\n",
      "[110]\tvalidation_0-error:0.01704\n",
      "[111]\tvalidation_0-error:0.01704\n",
      "[112]\tvalidation_0-error:0.01704\n",
      "[113]\tvalidation_0-error:0.01704\n",
      "[114]\tvalidation_0-error:0.01704\n",
      "[115]\tvalidation_0-error:0.01704\n",
      "[116]\tvalidation_0-error:0.01704\n",
      "[117]\tvalidation_0-error:0.01768\n",
      "[118]\tvalidation_0-error:0.01768\n",
      "[119]\tvalidation_0-error:0.01801\n",
      "[120]\tvalidation_0-error:0.01768\n",
      "[121]\tvalidation_0-error:0.01736\n",
      "[122]\tvalidation_0-error:0.01801\n",
      "[123]\tvalidation_0-error:0.01768\n",
      "[124]\tvalidation_0-error:0.01768\n",
      "[125]\tvalidation_0-error:0.01801\n",
      "[126]\tvalidation_0-error:0.01833\n",
      "[127]\tvalidation_0-error:0.01801\n",
      "[128]\tvalidation_0-error:0.01736\n",
      "[129]\tvalidation_0-error:0.01768\n",
      "[130]\tvalidation_0-error:0.01801\n",
      "[131]\tvalidation_0-error:0.01801\n",
      "[132]\tvalidation_0-error:0.01833\n",
      "[133]\tvalidation_0-error:0.01865\n",
      "[134]\tvalidation_0-error:0.01865\n",
      "[135]\tvalidation_0-error:0.01865\n",
      "[136]\tvalidation_0-error:0.01897\n",
      "[137]\tvalidation_0-error:0.01929\n",
      "[138]\tvalidation_0-error:0.01961\n",
      "[139]\tvalidation_0-error:0.01961\n",
      "[140]\tvalidation_0-error:0.01865\n",
      "[141]\tvalidation_0-error:0.01929\n",
      "[142]\tvalidation_0-error:0.01929\n",
      "[143]\tvalidation_0-error:0.01961\n",
      "[144]\tvalidation_0-error:0.01929\n",
      "[145]\tvalidation_0-error:0.01865\n",
      "[146]\tvalidation_0-error:0.01897\n",
      "[147]\tvalidation_0-error:0.01961\n",
      "[148]\tvalidation_0-error:0.01961\n",
      "[149]\tvalidation_0-error:0.01929\n",
      "[150]\tvalidation_0-error:0.01961\n",
      "[151]\tvalidation_0-error:0.01929\n",
      "[152]\tvalidation_0-error:0.01929\n",
      "[153]\tvalidation_0-error:0.01929\n",
      "[154]\tvalidation_0-error:0.01897\n",
      "[155]\tvalidation_0-error:0.01897\n",
      "[156]\tvalidation_0-error:0.01897\n",
      "[157]\tvalidation_0-error:0.01865\n",
      "[158]\tvalidation_0-error:0.01865\n",
      "[159]\tvalidation_0-error:0.01929\n",
      "[160]\tvalidation_0-error:0.01929\n",
      "[161]\tvalidation_0-error:0.01929\n",
      "[162]\tvalidation_0-error:0.01929\n",
      "[163]\tvalidation_0-error:0.01929\n",
      "[164]\tvalidation_0-error:0.01929\n",
      "[165]\tvalidation_0-error:0.01897\n",
      "[166]\tvalidation_0-error:0.01929\n",
      "[167]\tvalidation_0-error:0.01929\n",
      "[168]\tvalidation_0-error:0.01929\n",
      "[169]\tvalidation_0-error:0.01897\n",
      "[170]\tvalidation_0-error:0.01865\n",
      "[171]\tvalidation_0-error:0.01865\n",
      "[172]\tvalidation_0-error:0.01833\n",
      "[173]\tvalidation_0-error:0.01833\n",
      "[174]\tvalidation_0-error:0.01833\n",
      "[175]\tvalidation_0-error:0.01833\n",
      "[176]\tvalidation_0-error:0.01865\n",
      "[177]\tvalidation_0-error:0.01833\n",
      "[178]\tvalidation_0-error:0.01768\n",
      "[179]\tvalidation_0-error:0.01768\n",
      "[180]\tvalidation_0-error:0.01768\n",
      "[181]\tvalidation_0-error:0.01833\n",
      "[182]\tvalidation_0-error:0.01833\n",
      "[183]\tvalidation_0-error:0.01833\n",
      "[184]\tvalidation_0-error:0.01801\n",
      "[185]\tvalidation_0-error:0.01768\n",
      "[186]\tvalidation_0-error:0.01768\n",
      "[187]\tvalidation_0-error:0.01768\n",
      "[188]\tvalidation_0-error:0.01801\n",
      "[189]\tvalidation_0-error:0.01801\n",
      "[190]\tvalidation_0-error:0.01768\n",
      "[191]\tvalidation_0-error:0.01768\n",
      "Accuracy: 98.33%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=2, n_estimators=5000)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric=\"error\"\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, early_stopping_rounds=100)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a028ddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'n_estimators': 100}\n",
      "Best score: 0.98392\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators':[2, 25, 50, 75, 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a87c842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'max_depth': 8, 'n_estimators': 50}\n",
      "Best score: 0.98159\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 3, 4, 6, 7, 8], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f12fc43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'max_depth': 7, 'n_estimators': 100}\n",
      "Best score: 0.98561\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 3, 4, 6, 7, 8], \n",
    "                    'n_estimators':[2, 50, 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d385fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'learning_rate': 0.4, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.79804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "402435ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 50}\n",
      "Best score: 0.79257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'min_child_weight':[1, 2, 3, 4, 5], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6223bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'max_depth': 1, 'n_estimators': 50, 'subsample': 1}\n",
      "Best score: 0.79257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bf1809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'learning_rate': 0.5, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 2, 'subsample': 0.9}\n",
      "Best score: 0.81323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'min_child_weight':[1, 2, 3, 4, 5], \n",
    "                    'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                    'max_depth':[1, 2, 3, 4, 5], \n",
    "                    'n_estimators':[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "894d2001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': None, 'learning_rate': 0.3}\n",
      "Best score: 0.98271\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'min_child_weight':[1, 2, 3, 4, 5], \n",
    "                    'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                    'max_depth':[1, 2, 3, 4, 5, None], \n",
    "                    'n_estimators':[2, 25, 50, 75, 100]}, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e9f8aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'colsample_bytree': 0.7, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.79466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "539656f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'colsample_bylevel': 0.7, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.79466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79d4e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'colsample_bylevel': 0.7, 'colsample_bynode': 1, 'colsample_bytree': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.79466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bynode':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ebd59fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'colsample_bylevel': 0.9, 'colsample_bynode': 0.5, 'colsample_bytree': 0.8, 'gamma': 0, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.78887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shh28\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'gamma':[0, 0.01, 0.05, 0.1, 0.5, 1, 2, 3], \n",
    "                    'colsample_bylevel':[0.9], \n",
    "                    'colsample_bytree':[0.8], \n",
    "                    'colsample_bynode':[0.5], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39cd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9807bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
