{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725ddefb",
   "metadata": {},
   "source": [
    "## 9장 범주형\n",
    "데이터 분석에서 수치형 다음으로 많이 다루는 것이 범주형 입니다.\n",
    "범주형은 가질 수 있는 값의 종류가 정해진 값을 의미합니다.\n",
    "예를들어, 우리나라의 행정구역이 있고, 회원, 비회원 구분도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74110f5d",
   "metadata": {},
   "source": [
    "# 범주형으로 변환\n",
    "범주형은 데이터의 크기를 줄이는 데 유용합니다. 범줏값의 마스터 데이터와 각 데이터의 범줏값 인덱스 데이터로 나누어 데이터를 보존합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826e7ea8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'customer.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-23e23eba2e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcustomer_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'customer.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcustomer_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'customer.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "customer_tb = pd.read_csv('customer.csv')\n",
    "customer_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb[['sex_is_man']] = (customer_tb[['sex']] == 'man').astype(bool)\n",
    "customer_tb['sex_is_man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75cbb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_tb['sex_c'] = pd.Categorical(customer_tb['sex'], categories=['man', 'woman'])\n",
    "customer_tb['sex_c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0308e",
   "metadata": {},
   "source": [
    "pandas의 Categorical 함수를 이용한 범주화 입니다.\n",
    "\n",
    "다른 방법으론 astype 함수를 이용가능합니다.\n",
    "\n",
    "그러나 astype 함수를 이용시에는 마스터 데이터를 지정할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab146ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['sex_c'] = customer_tb['sex_c'].astype('category')\n",
    "customer_tb['sex_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabe255",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['sex_c'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b26515",
   "metadata": {},
   "source": [
    "cat함수 이용시 범주화 시킬 데이터가 들어있습니다.\n",
    "\n",
    "여기에 codes 함수를 이용시 각 범주의 인덱스로 구성된 Series를 반환합니다.\n",
    "\n",
    "예를들어 이번의 경우 남자는 0, 여자는 1로 해서 각 인덱스마다 코드를 반환받습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c880a",
   "metadata": {},
   "source": [
    "# 더미 변수화\n",
    "더미변수화 라는 것은 범주형 변수를 연속형 변수로 바꾸는 것입니다.\n",
    "\n",
    "이러한 처리를 통해 연속형 변수로만 가능한 분석기법을 범주형 변수에 사용가능하게 해줍니다.\n",
    "\n",
    "즉 예를 들어 남녀 성을 더미 변수화 하는 경우, 남성이 아니면, 무조건 여성입니다.\n",
    "\n",
    "그러나 더미 변수화를 통해 남성의 경우 0, 여성의 경우 1을 가지는 더미 변수화를 하여 수치화를 진행하는 경우\n",
    "\n",
    "이를 선형회귀에 이용가능합니다.\n",
    "\n",
    "선형회귀에는 남성, 여성 대입을 하는 것은 안되지만, 0, 1을 넣는 것은 가능하기때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['sex'] = pd.Categorical(customer_tb['sex'])\n",
    "\n",
    "dummy_vars = pd.get_dummies(customer_tb['sex'], drop_first=False)\n",
    "dummy_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0a3e8",
   "metadata": {},
   "source": [
    "여기서 drop_first = False 의 의미를 대략설명하자면,\n",
    "\n",
    "중학교 범주화에서 1 : 저학년 2 : 중간학년, 3 : 고학년 이렇게 구분가능한거를\n",
    "\n",
    "1,2 ,'둘다 아닌 거' 이렇게 세개로 구분합니다.\n",
    "\n",
    "중학교의 경우 1학년, 2학년 아니면 자동으로 3학년을 결정되기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9fa96d",
   "metadata": {},
   "source": [
    "# 범줏값의 집약\n",
    "범주형을 통해 더미 데이터화를 할 경우 일반적인 경우보다 적은 특성을 학습하므로, 과적합 발생확률이 높습니다.\n",
    "\n",
    "따라서 데이터 개수를 늘려주기 위해 비슷한 범주값들 끼리 묶어 데이터 개수를 늘리는 방법이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b629ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ed59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['age_rank'] = pd.Categorical(np.floor(customer_tb['age']/10)*10)\n",
    "customer_tb['age_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80739416",
   "metadata": {},
   "source": [
    "카테고리화 하여서 값의 경우가 20대부터 80대가 있습니다.\n",
    "\n",
    "우리의 목표는 60, 70, 80을 60대 이상으로 묶는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['age_rank'].cat.add_categories(['60 이상'], inplace = True)\n",
    "customer_tb['age_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4ec0d",
   "metadata": {},
   "source": [
    "add_categories는 범주형 마스터 데이터를 추가하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7382b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb.loc[customer_tb['age_rank'].isin([60.0, 70.0, 80.0]), 'age_rank'] = '60 이상'\n",
    "customer_tb['age_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830282c",
   "metadata": {},
   "source": [
    "isin()함수를 이용할 경우 60대 이상인 범주값들에 대해 있는 경우 true가 반환됩니다.\n",
    "\n",
    "그리고 loc[]은 안에 boolean 타입의 Series를 대입시켜 True 인 것들의 row를 반환해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec49a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['age_rank'].cat.remove_unused_categories(inplace = True)\n",
    "customer_tb['age_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728b803",
   "metadata": {},
   "source": [
    "remove_unused_categories()함수를 통해 쓰지않는 범주형 마스터 데이터를 제거합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb46ac",
   "metadata": {},
   "source": [
    "# 범주값의 조합\n",
    "범주값을 줄이는 방법도 있지만, 조합하여 새로운 범주값을 추가하는 방법도 있습니다.\n",
    "\n",
    "예를들어 20대와 남성을 합치면 20대 남성 이라는 새로운 범주값을 추가할 수 있습니다.\n",
    "\n",
    "그러나 조합을 이용할 경우 더미 데이터의 경우의 수도 늘어나 처리할 데이터의 종류도 늘어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['sex and age'] = pd.Categorical(customer_tb[['sex', 'age']]\n",
    "                                           .apply(lambda x: '{}_{}'.format(x[0], np.floor(x[1]/10) * 10),\n",
    "                                                 axis = 1))\n",
    "customer_tb['sex and age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16fba0f",
   "metadata": {},
   "source": [
    "# 범주형의 수치화\n",
    "예를들어 특정 물건에 대한 불량률을 계산하고 싶은경우, 전체 물건 종류에 대한 개수를 구하고,\n",
    "\n",
    "그 다음 불량인 물건의 개수에 대해 구한다음, 두번째 값에 대해 첫 번째 값을 나눠주면 불량율이 나옵니다.\n",
    "\n",
    "즉 범주형 데이터로 다른 수치형 데이터를 뽑아낸 것 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "production = pd.read_csv('production.csv')\n",
    "production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04133ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_cnt_per_type = production.query('fault_flg').groupby('type')['fault_flg'].count()\n",
    "fault_cnt_per_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fd3aa5",
   "metadata": {},
   "source": [
    "query 함수를 통해 fault_flg가 true 인거를 추출했습니다.\n",
    "\n",
    "즉 결함이 있는 것만 뽑았습니다.\n",
    "\n",
    "그다음 type 별로 묶어준다음 true인 개수를 세었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_cnt = production.groupby('type')['fault_flg'].count()\n",
    "type_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f5fb49",
   "metadata": {},
   "source": [
    "전체의 개수 입니다.\n",
    "\n",
    "즉 여기서 먼저 구한 거에 나중에 구한 거를 나눠주면 type별 불량품의 개수가 나오게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "production['type_fault_rate'] = production[['type', 'fault_flg']].apply(lambda x:\n",
    "                                                                       (fault_cnt_per_type[x[0]] - int(x[1]))/\n",
    "                                                                       (type_cnt[x[0]] - 1), axis = 1)\n",
    "\n",
    "production['type_fault_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2fedc",
   "metadata": {},
   "source": [
    "# 범주형의 보완\n",
    "범주형의 경우 일정한 수치값을 가지고 있는 것이 아니기 때문에 결손값의 보완도 군집으로 접근하여야 합니다.\n",
    "\n",
    "이중 많이 사용되는 방법이 KNN 기법이고, sklearn을 이용하여 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "production_missc_tb = pd.read_csv('production_missing_category.csv')\n",
    "production_missc_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50306300",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_missc_tb.replace('None', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1f687",
   "metadata": {},
   "source": [
    "결측치를 처리하기 위해선 컴퓨터에 결측치 라는 것을 가르쳐주기 위해 넘파이에서 nan함수를 이용하여\n",
    "\n",
    "비어있는 곳에 'None'이라고 값을 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = production_missc_tb.dropna(subset=['type'], inplace=False)\n",
    "train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4427f",
   "metadata": {},
   "source": [
    "결손이 없는 데이터을 뽑기 위해 dropna 함수를 통해 없는 값들을 전부 버려주었습니다.\n",
    "\n",
    "subset = [column]을 해줄경우 열에 대해 값이 없는 경우만 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9fa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = production_missc_tb.loc[production_missc_tb.index.difference(train.index),:]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab20876",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "kn.fit(train[['length', 'thickness']], train['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034f9d2",
   "metadata": {},
   "source": [
    "KNN방식은 길이를 측정하는 방식으로 군집도를 결정하는 방식으로 무엇의 길이를 잴지 정해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26484df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['type'] = kn.predict(test[['length', 'thickness']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b40fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
